{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "k3iYdKDpeoQO"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import graphviz  # To visualize our learned decision trees.\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "XyBb25VpexN2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass  sex   age  sibsp  parch     fare  embarked  class  who  \\\n",
       "0           0       3    1  22.0      1      0   7.2500         2      2    1   \n",
       "1           1       1    0  38.0      1      0  71.2833         0      0    2   \n",
       "2           1       3    0  26.0      0      0   7.9250         2      2    2   \n",
       "3           1       1    0  35.0      1      0  53.1000         2      0    2   \n",
       "4           0       3    1  35.0      0      0   8.0500         2      2    1   \n",
       "..        ...     ...  ...   ...    ...    ...      ...       ...    ...  ...   \n",
       "886         0       2    1  27.0      0      0  13.0000         2      1    1   \n",
       "887         1       1    0  19.0      0      0  30.0000         2      0    2   \n",
       "888         0       3    0   NaN      1      2  23.4500         2      2    2   \n",
       "889         1       1    1  26.0      0      0  30.0000         0      0    1   \n",
       "890         0       3    1  32.0      0      0   7.7500         1      2    1   \n",
       "\n",
       "     adult_male  deck  embark_town alive  alone  \n",
       "0             1    -1            2    no  False  \n",
       "1             0     2            0   yes  False  \n",
       "2             0    -1            2   yes   True  \n",
       "3             0     2            2   yes  False  \n",
       "4             1    -1            2    no   True  \n",
       "..          ...   ...          ...   ...    ...  \n",
       "886           1    -1            2    no   True  \n",
       "887           0     1            2   yes   True  \n",
       "888           0    -1            2    no  False  \n",
       "889           1     2            0   yes   True  \n",
       "890           1    -1            1    no   True  \n",
       "\n",
       "[891 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's revisit our old friend, \"titanic\", again.\n",
    "titanic = sns.load_dataset('titanic')  # Contains about a third of the Titanic data\n",
    "\n",
    "# Convert string-valued columns to numerical categorical values.\n",
    "for column in ('survived', 'sex', 'embarked', 'class', 'who', 'adult_male', 'deck', 'embark_town'):\n",
    "  titanic[column] = pd.Categorical(titanic[column]).codes\n",
    "titanic  # Preview the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xb2RzJhlg1GX"
   },
   "outputs": [],
   "source": [
    "# Before we move forward, let's look at our features, generating a diagram like\n",
    "# the one we talked about in Lecture 7.\n",
    "# Code based on: https://scikit-learn.org/stable/auto_examples/inspection/plot_permutation_importance_multicollinear.html#sphx-glr-auto-examples-inspection-plot-permutation-importance-multicollinear-py\n",
    "import scipy\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 8))\n",
    "corr = scipy.stats.spearmanr(titanic).correlation\n",
    "\n",
    "# Ensure the correlation matrix is symmetric\n",
    "corr = (corr + corr.T) / 2\n",
    "np.fill_diagonal(corr, 1)\n",
    "\n",
    "# We convert the correlation matrix to a distance matrix before performing\n",
    "# hierarchical clustering using Ward's linkage.\n",
    "distance_matrix = 1 - np.abs(corr)\n",
    "dist_linkage = scipy.cluster.hierarchy.ward(scipy.spatial.distance.squareform(distance_matrix))\n",
    "dendro = scipy.cluster.hierarchy.dendrogram(\n",
    "    dist_linkage, labels=titanic.columns.values.tolist(), ax=ax1, leaf_rotation=90\n",
    ")\n",
    "dendro_idx = np.arange(0, len(dendro[\"ivl\"]))\n",
    "\n",
    "ax2.imshow(corr[dendro[\"leaves\"], :][:, dendro[\"leaves\"]])\n",
    "ax2.set_xticks(dendro_idx)\n",
    "ax2.set_yticks(dendro_idx)\n",
    "ax2.set_xticklabels(dendro[\"ivl\"], rotation=\"vertical\")\n",
    "ax2.set_yticklabels(dendro[\"ivl\"])\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "# Anything stand out? Which features might we remove? And what's about to be a\n",
    "# huge problem for predicting 'survived' from the other featuers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5e60Qm2Ih0P5"
   },
   "outputs": [],
   "source": [
    "# Drop 'alive', 'pclass'\n",
    "titanic.drop(['alive', 'pclass'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OAgP1bpziE-C"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imp = SimpleImputer(strategy=\"most_frequent\")  # Using most-frequent for categorical data.\n",
    "imputed_titanic = imp.fit_transform(titanic)  # This creates a new Numpy array with missing values imputed.\n",
    "titanic = pd.DataFrame(imputed_titanic, columns=titanic.columns, index=titanic.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kr9s6gG7fSgW"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(titanic.drop(\"survived\", axis=1), titanic[\"survived\"], test_size=0.2, random_state=5, shuffle=True)\n",
    "y_train = y_train.astype('int')  # For some reason these are just 'object' typed when extracted.\n",
    "y_test = y_test.astype('int')\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MZWSpEZSe5pc"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier(\n",
    "\tcriterion=\"entropy\",\n",
    "\tmax_depth=3,  # What happens if you lower or raise this value?\n",
    "\tclass_weight=None,\n",
    "\trandom_state=0\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "print(f'DT, depth=3 acc: {model.score(X_test, y_test):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "APbZxGUekVh6"
   },
   "outputs": [],
   "source": [
    "# Just for reference, train a few baselines\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "gnb = GaussianNB(var_smoothing=0.0)\n",
    "gnb.fit(X_train, y_train)\n",
    "print(f'Gaussian NB acc: {gnb.score(X_test, y_test):.2%}')\n",
    "\n",
    "bnb = BernoulliNB(alpha=1)\n",
    "bnb.fit(X_train, y_train)\n",
    "print(f'Bernoulli NB acc: {bnb.score(X_test, y_test):.2%}')\n",
    "\n",
    "lr = LogisticRegression(\n",
    "  penalty=\"none\",\n",
    "\tclass_weight=None,\n",
    "\trandom_state=0,\n",
    "\tsolver=\"lbfgs\",\n",
    "\tmulti_class=\"multinomial\",\n",
    "\tmax_iter=500)\n",
    "lr.fit(X_train, y_train)\n",
    "print(f'Logistic Regression acc: {lr.score(X_test, y_test):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MIOCh18yf05T"
   },
   "outputs": [],
   "source": [
    "# So what's actually being learned? Consider starting with a depth=1 tree.\n",
    "import graphviz\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "dot_data = export_graphviz(model, feature_names=X_train.columns.values, out_file=None)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yr1LJqe8yvdc"
   },
   "outputs": [],
   "source": [
    "# Why was adult male the first choice?\n",
    "sns.histplot(data=titanic, x=\"adult_male\", hue=\"survived\", multiple=\"dodge\")\n",
    "# Ignoring the ugly x-axis, clear how each node high purity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7bj93qUklt61"
   },
   "outputs": [],
   "source": [
    "# How about RandomForests\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100, criterion='entropy', max_depth=3, random_state=0)  # This algorithm involves randomness!\n",
    "rfc.fit(X_train, y_train)\n",
    "print(f'RF, depth=3 acc: {rfc.score(X_test, y_test):.2%}')  # No gain in accuracy. The dataset is a bit small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jvgpH4FK2cI_"
   },
   "outputs": [],
   "source": [
    "# Code based on: https://scikit-learn.org/stable/auto_examples/inspection/plot_permutation_importance_multicollinear.html#sphx-glr-auto-examples-inspection-plot-permutation-importance-multicollinear-py\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "result = permutation_importance(rfc, X_train, y_train, n_repeats=10, random_state=42)\n",
    "perm_sorted_idx = result.importances_mean.argsort()\n",
    "\n",
    "tree_importance_sorted_idx = np.argsort(rfc.feature_importances_)\n",
    "tree_indices = np.arange(0, len(rfc.feature_importances_)) + 0.5\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 8))\n",
    "ax1.barh(tree_indices, rfc.feature_importances_[tree_importance_sorted_idx], height=0.7)\n",
    "ax1.set_yticks(tree_indices)\n",
    "feature_names = X_train.columns.values\n",
    "ax1.set_yticklabels(feature_names[tree_importance_sorted_idx])\n",
    "ax1.set_ylim((0, len(rfc.feature_importances_)))\n",
    "ax2.boxplot(\n",
    "    result.importances[perm_sorted_idx].T,\n",
    "    vert=False,\n",
    "    labels=feature_names[perm_sorted_idx],\n",
    ")\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "# Note how the two don't always match. In general, feature importance (which here\n",
    "# refers to mean decrease in purity across all DTs) can be somewhat less informative\n",
    "# then permutation importance because they skew towards common features and are \n",
    "# estimated on training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MLoY5umB7sGz"
   },
   "outputs": [],
   "source": [
    "# For completeness, gradient boosted decision trees. Not any better either.\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbc = GradientBoostingClassifier(n_estimators=100, max_depth=5, random_state=0)\n",
    "gbc.fit(X_train, y_train)\n",
    "print(f'Boosted DT, depth=3 acc: {gbc.score(X_test, y_test):.2%}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
